11.25
Markov models for language: A naive but sometimes amusing model for language is a Markov
model. In this model, language is assumed to be a sequence in which the next word is
drawn from a distribution that depends only on the current word. The model can be
elaborated slightly to one in which the next word depends on the current word along with
the previous m words, for some fixed value of m.
You will write functions that fit such models from text and that generate new text from the
fitted model. You can use as input text either the books we used in homework 1 or text of
your choice.

11.29
masterpiece (sarcastic way)
---
train with pg244, pg1661
Sample 1:
Scene.” “is such a winding staircases, and the streets. “you should be nothing whatever. there was not appear to an exceeding small.” john h. for any rate.’ she bade me to love of an exceeding thinness. i only are one or hypertext form. any statements concerning tax identification number of the lid from the shuttered up. water some time to have removed it all about forty-three or else had already deeply as i had no other,’ said he; “my cabby drove fast. i fancy.” “good god!” i ran up the rolling cloud of any part of bakers, and discontinue all
Sample 2:
Then composed himself, shrugged his story. “i shall call her, but the sunlight beneath us. we should dwell. you want, then?’ i gave a tall, stout official police to night. he squeezed out again. she left to warn you can get rid of those whom i have them with pleasure. “i’ll follow the disappearance of the streets which you gentlemen should be some most singular adventures of compliance. to mine has.” “your conversation i cried a stir, sir,” cried a moment to a wash,” remarked sherlock holmes cut himself seems to which looked round the injuries. there lay as good%

---